{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090ed9a7-4c8e-472a-b5c0-6b1853c76be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cfb1757-05f7-4e1c-9c7e-dcd2bb94a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 可用: True\n",
      "PyTorch 版本: 2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA 可用:\", torch.cuda.is_available())\n",
    "print(\"PyTorch 版本:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56af4b72-273e-433c-9a62-af8006f7b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62d8c80-2142-4ba6-8c15-ae3112cd7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': r'E:\\archive', \n",
    "    'batch_size': 64,\n",
    "    'lr': 3e-4,\n",
    "    'epochs': 50,\n",
    "    'num_classes': 6,\n",
    "    'temperature': 3,\n",
    "    'alpha': 0.7,  # 蒸馏损失权重\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5f5ba23-36b1-4d66-bea5-9e14990cb3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingBehaviorDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotations_file, classes_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取类别文件\n",
    "        with open(classes_file, 'r') as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # 读取标注文件\n",
    "        self.samples = []\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                parts = line.strip().split(' ')\n",
    "                if not parts:\n",
    "                    continue\n",
    "                try:\n",
    "                    class_id = int(parts[-1].split(',')[-1])\n",
    "                    img_name = parts[0]\n",
    "                    self.samples.append((img_name, class_id))\n",
    "                except:\n",
    "                    print(f\"跳过无效标注行: {line}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 最大重试次数\n",
    "        max_retries = 5\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                img_name, target = self.samples[idx]\n",
    "                img_path = os.path.join(self.root_dir, img_name)\n",
    "                image = Image.open(img_path).convert('L')  # 加载灰度图像\n",
    "\n",
    "                if self.transform:\n",
    "                    image = self.transform(image)\n",
    "\n",
    "                return image, target  # 成功加载，返回结果\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"加载图像失败 (尝试 {attempt+1}/{max_retries}): {img_path} - {e}\")\n",
    "                idx = (idx + 1) % len(self)  # 移动到下一个索引\n",
    "\n",
    "        # 达到最大重试次数仍未找到有效图像\n",
    "        raise RuntimeError(\"达到最大重试次数，无法加载有效图像。请检查数据集完整性\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbd8ab53-ab6b-4387-ac06-4a66e2af24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingBehaviorDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotations_file, classes_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取类别文件\n",
    "        with open(classes_file, 'r') as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # 读取标注文件\n",
    "        self.samples = []\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                # 按空格分割，取最后一个元素（包含逗号）\n",
    "                parts = line.split(' ')\n",
    "                if len(parts) < 2:\n",
    "                    continue  # 跳过无效行\n",
    "\n",
    "                # 提取最后一个字段（包含逗号）\n",
    "                last_part = parts[-1]\n",
    "\n",
    "                # 再按逗号分割，取最后一个值作为类别ID\n",
    "                if ',' in last_part:\n",
    "                    class_id_str = last_part.split(',')[-1]\n",
    "                else:\n",
    "                    class_id_str = last_part\n",
    "\n",
    "                # 转换为整数\n",
    "                try:\n",
    "                    class_id = int(class_id_str)\n",
    "                except ValueError:\n",
    "                    print(f\"跳过无效标注行: {line}\")\n",
    "                    continue\n",
    "\n",
    "                # 提取图片名\n",
    "                img_name = parts[0]\n",
    "\n",
    "                # 添加到样本列表\n",
    "                self.samples.append((img_name, class_id))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, target = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('L')\n",
    "        except Exception as e:\n",
    "            print(f\"加载图像失败: {img_path} - {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05bfe4b0-cab2-4e14-8aec-696dfeda471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e32497-c373-45d1-936b-d24c14f59c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "跳过无效标注行: gA_4_s2_ir_face_mp4-440_jpg.rf.f0ab9d03d718ac287cac6fca394783d0.jpg\n",
      "\n",
      "跳过无效标注行: gA_4_s2_ir_face_mp4-440_jpg.rf.fa7c39ef44d869bdab6c298c89442f19.jpg\n",
      "\n",
      "跳过无效标注行: gB_9_s1_2019-03-07T16-36-24-01-00_ir_face_mp4-401_jpg.rf.4a274f58e714facd11a3693a3325c3d5.jpg\n",
      "\n",
      "跳过无效标注行: gB_9_s1_2019-03-07T16-36-24-01-00_ir_face_mp4-401_jpg.rf.c507475339c83c2de42f2400987923d2.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    train_dataset = DrivingBehaviorDataset(\n",
    "        root_dir=os.path.join(config['data_path'], 'train'),\n",
    "        annotations_file=os.path.join(config['data_path'], 'train', '_annotations.txt'),\n",
    "        classes_file=os.path.join(config['data_path'], 'train', '_classes.txt'),\n",
    "        transform=transform\n",
    "    )\n",
    "    val_dataset = DrivingBehaviorDataset(\n",
    "        root_dir=os.path.join(config['data_path'], 'valid'),\n",
    "        annotations_file=os.path.join(config['data_path'], 'valid', '_annotations.txt'),\n",
    "        classes_file=os.path.join(config['data_path'], 'valid', '_classes.txt'),\n",
    "        transform=transform\n",
    "    )\n",
    "    test_dataset = DrivingBehaviorDataset(\n",
    "        root_dir=os.path.join(config['data_path'], 'test'),\n",
    "        annotations_file=os.path.join(config['data_path'], 'test', '_annotations.txt'),\n",
    "        classes_file=os.path.join(config['data_path'], 'test', '_classes.txt'),\n",
    "        transform=transform\n",
    "    )\n",
    "    return (\n",
    "        DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4),\n",
    "        DataLoader(val_dataset, batch_size=config['batch_size'], num_workers=4),\n",
    "        DataLoader(test_dataset, batch_size=config['batch_size'], num_workers=4)\n",
    "    )\n",
    "\n",
    "train_loader, val_loader, test_loader = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3b78884-620f-43b3-b442-fe4649cc2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "teacher_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False)\n",
    "teacher_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(1280, config['num_classes']),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "teacher_model = teacher_model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d428a309-f31d-44c7-82fa-7e178f2f2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "student_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(1024, config['num_classes']),\n",
    "    nn.BatchNorm1d(config['num_classes'])\n",
    ")\n",
    "student_model = student_model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dda0a9f-0e15-4459-a568-9d638bb18c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureHook:\n",
    "    def __init__(self, model, layer_name):\n",
    "        self.hook = model._modules.get(layer_name).register_forward_hook(self.hook_fn)\n",
    "        self.feature = None\n",
    "\n",
    "    def hook_fn(self, module, input, output):\n",
    "        self.feature = output\n",
    "\n",
    "    def close(self):\n",
    "        self.hook.remove()\n",
    "\n",
    "teacher_hook = FeatureHook(teacher_model, 'features')\n",
    "student_hook = FeatureHook(student_model, 'features')\n",
    "\n",
    "# 动态温度系数（随训练过程递增）\n",
    "def dynamic_temperature(epoch, max_temp=20):\n",
    "    return min(config['temperature'] + epoch * 0.5, max_temp)\n",
    "\n",
    "# 改进的知识蒸馏损失函数（包含中间层蒸馏）\n",
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature, alpha):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.hard_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_div = nn.KLDivLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, y_s, y_t, labels, student_features, teacher_features):\n",
    "        # 输出层蒸馏\n",
    "        soft_loss = self.kl_div(\n",
    "            torch.log_softmax(y_s / self.temperature, dim=1),\n",
    "            torch.softmax(y_t / self.temperature, dim=1)\n",
    "        )\n",
    "        hard_loss = self.hard_loss(y_s, labels)\n",
    "        \n",
    "        feature_loss = self.mse_loss(student_features, teacher_features)\n",
    "        \n",
    "        return (1 - self.alpha) * soft_loss * (self.temperature**2) + self.alpha * hard_loss + 0.3 * feature_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2865907-6719-4c16-82dc-6b4918b7e089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, teacher, loader, optimizer, loss_fn, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(inputs)\n",
    "            teacher_features = teacher_hook.feature\n",
    "        \n",
    "        student_logits = model(inputs)\n",
    "        student_features = student_hook.feature\n",
    "\n",
    "        # 动态温度系数\n",
    "        temp = dynamic_temperature(epoch)\n",
    "        loss = loss_fn(student_logits, teacher_logits, labels, student_features, teacher_features)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = student_logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b48fd6d-5cf3-4f0c-b5a0-a30b46f7e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3929cf9-ec77-49f2-9442-fc729b785414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759d92de-43e0-4ac8-89d8-9a0de5966631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, data_loader, device, class_names, num_images=6):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Pred: {class_names[preds[j]]} | True: {class_names[labels[j]]}')\n",
    "                plt.imshow(inputs[j].cpu().permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "                if images_so_far == num_images:\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig('prediction_examples.png')\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "                    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b7067-ed44-457b-b8f5-f421225e1e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859d4a5f-c224-485b-b2e6-df349604da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DrivingBehaviorDataset(\n",
    "    root_dir=os.path.join(config['data_path'], 'train'),\n",
    "    annotations_file=os.path.join(config['data_path'], 'train', '_annotations.txt'),\n",
    "    classes_file=os.path.join(config['data_path'], 'train', '_classes.txt'),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebc39134-07d6-47c7-aaf4-7085ae171735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.DrivingBehaviorDataset at 0x19644364430>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4f45e7-7c18-488d-a096-a7f473836f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrivingBehaviorDataset(\n",
    "    root_dir=os.path.join(config['data_path'], 'test'),\n",
    "    annotations_file=os.path.join(config['data_path'], 'test', '_annotations.txt'),\n",
    "    classes_file=os.path.join(config['data_path'], 'test', '_classes.txt'),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48cfef6d-03fe-4bf9-afba-fc40e988f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41af9ae5-cd0b-44b4-9b7e-18a9f9c99651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教师模型（EfficientNetV2）\n",
    "teacher_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)  # 推荐使用 DEFAULT\n",
    "teacher_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False)\n",
    "teacher_model.classifier[1] = nn.Linear(1280, config['num_classes'])\n",
    "teacher_model = teacher_model.to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1def58f-64fc-4a78-b754-e909309d1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学生模型（MobileNetV3 Small）\n",
    "student_model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "student_model.classifier[3] = nn.Linear(1024, config['num_classes'])\n",
    "student_model = student_model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4760cd61-acc2-4a6b-9402-11bb8ad003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd6688f-3014-4844-b250-0533beafa3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet_V2_S_Weights.IMAGENET1K_V1\n"
     ]
    }
   ],
   "source": [
    "print(models.EfficientNet_V2_S_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeae38d2-5f7f-436f-ae37-484a1d34b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(teacher_model.features[0][0].in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09d2809c-245b-456c-a043-4be6c1e17658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature, alpha):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.hard_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_div = nn.KLDivLoss()\n",
    "\n",
    "    def forward(self, y_s, y_t, labels):\n",
    "        soft_loss = self.kl_div(\n",
    "            torch.log_softmax(y_s / self.temperature, dim=1),\n",
    "            torch.softmax(y_t / self.temperature, dim=1)\n",
    "        )\n",
    "        hard_loss = self.hard_loss(y_s, labels)\n",
    "        return (1 - self.alpha) * soft_loss * (self.temperature**2) + self.alpha * hard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be604b8a-d584-4510-9d56-32cfbd3fa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, teacher, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(inputs)\n",
    "        student_logits = model(inputs)\n",
    "\n",
    "        loss = loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = student_logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df38c78-2644-4c18-af63-f5aafd2c90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef84857c-223a-4fcd-a75b-b272e1b8e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b03c44cf-f261-49d2-9230-bc3709da615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    try:\n",
    "        # 确保输入为numpy数组\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_names, \n",
    "                    yticklabels=class_names,\n",
    "                    cbar=False)  # 避免颜色条遮挡\n",
    "        plt.xticks(rotation=45)  # 防止标签重叠\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.xlabel('Predicted', fontsize=12)\n",
    "        plt.ylabel('True', fontsize=12)\n",
    "        plt.title('Confusion Matrix', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png', dpi=300)  # 增加保存分辨率\n",
    "        plt.show(block=True)  # 确保阻塞显示\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"绘图失败: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c80d6a-f1bf-4caf-b72d-450ccce5403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_plots():\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.ion()\n",
    "\n",
    "def update_plots(epoch, train_loss, train_acc, val_loss, val_acc, losses, accuracies):\n",
    "    epochs = list(range(1, epoch + 2))\n",
    "    losses['train'].append(train_loss)\n",
    "    losses['val'].append(val_loss)\n",
    "    accuracies['train'].append(train_acc)\n",
    "    accuracies['val'].append(val_acc)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses['train'], label='Train Loss')\n",
    "    plt.plot(epochs, losses['val'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracies['train'], label='Train Acc')\n",
    "    plt.plot(epochs, accuracies['val'], label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93ab4c-5022-485f-b80e-effd1d12c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, data_loader, device, class_names, num_images=6):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Pred: {class_names[preds[j]]} | True: {class_names[labels[j]]}')\n",
    "                plt.imshow(inputs[j].cpu().permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    plt.show()\n",
    "                    return\n",
    "\n",
    "# 主训练流程\n",
    "def main():\n",
    "    teacher = teacher_model\n",
    "    student = student_model\n",
    "\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.AdamW(student.parameters(), lr=config['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    loss_fn = DistillationLoss(config['temperature'], config['alpha'])\n",
    "\n",
    "    best_acc = 0\n",
    "    losses = {'train': [], 'val': []}\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    initialize_plots()\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(student, teacher, train_loader, optimizer, loss_fn, config['device'])\n",
    "        val_acc, _, _ = evaluate(student, val_loader, config['device'])\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        update_plots(epoch, train_loss, train_acc, train_loss, val_acc, losses, accuracies)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(student.state_dict(), 'best_student_model.pth')\n",
    "\n",
    "    student.load_state_dict(torch.load('best_student_model.pth'))\n",
    "    test_acc, preds, labels = evaluate(student, test_loader, config['device'])\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels, preds))\n",
    "\n",
    "    class_names = ['DangerousDriving', 'Distracted', 'Drinking', 'SafeDriving', 'SleepyDriving', 'Yawn']\n",
    "    plot_confusion_matrix(labels, preds, class_names)\n",
    "    show_predictions(student, test_loader, config['device'], class_names, num_images=6)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7284dfa-2832-4271-82f0-30b18b3e25d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
