{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090ed9a7-4c8e-472a-b5c0-6b1853c76be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ad5891-1e76-4db7-8847-d9f26ac502ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\.conda\\envs\\pytorch\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfb1757-05f7-4e1c-9c7e-dcd2bb94a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 可用: True\n",
      "PyTorch 版本: 2.6.0+cu118\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA 可用:\", torch.cuda.is_available())\n",
    "print(\"PyTorch 版本:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56af4b72-273e-433c-9a62-af8006f7b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e62d8c80-2142-4ba6-8c15-ae3112cd7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': r'C:\\Users\\lenovo\\Desktop\\archive', \n",
    "    'batch_size': 64,\n",
    "    'lr': 3e-4,\n",
    "    'epochs': 50,\n",
    "    'num_classes': 6,\n",
    "    'temperature': 3,\n",
    "    'alpha': 0.7,  # 蒸馏损失权重\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd8ab53-ab6b-4387-ac06-4a66e2af24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingBehaviorDataset(Dataset):\n",
    "    def __init__(self, root_dir, annotations_file, classes_file, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # 读取类别文件\n",
    "        with open(classes_file, 'r') as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        # 读取标注文件\n",
    "        self.samples = []\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "\n",
    "                # 按空格分割，取最后一个元素（包含逗号）\n",
    "                parts = line.split(' ')\n",
    "                if len(parts) < 2:\n",
    "                    continue  # 跳过无效行\n",
    "\n",
    "                # 提取最后一个字段（包含逗号）\n",
    "                last_part = parts[-1]\n",
    "\n",
    "                # 再按逗号分割，取最后一个值作为类别ID\n",
    "                if ',' in last_part:\n",
    "                    class_id_str = last_part.split(',')[-1]\n",
    "                else:\n",
    "                    class_id_str = last_part\n",
    "\n",
    "                # 转换为整数\n",
    "                try:\n",
    "                    class_id = int(class_id_str)\n",
    "                except ValueError:\n",
    "                    print(f\"跳过无效标注行: {line}\")\n",
    "                    continue\n",
    "\n",
    "                # 提取图片名\n",
    "                img_name = parts[0]\n",
    "\n",
    "                # 添加到样本列表\n",
    "                self.samples.append((img_name, class_id))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, target = self.samples[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('L')\n",
    "        except Exception as e:\n",
    "            print(f\"加载图像失败: {img_path} - {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05bfe4b0-cab2-4e14-8aec-696dfeda471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "859d4a5f-c224-485b-b2e6-df349604da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DrivingBehaviorDataset(\n",
    "    root_dir=os.path.join(config['data_path'], 'train'),\n",
    "    annotations_file=os.path.join(config['data_path'], 'train', '_annotations.txt'),\n",
    "    classes_file=os.path.join(config['data_path'], 'train', '_classes.txt'),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4d51dc-d648-47d6-b85b-afe9f3abd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DrivingBehaviorDataset(\n",
    "    root_dir=os.path.join(config['data_path'], 'valid'),\n",
    "    annotations_file=os.path.join(config['data_path'], 'valid', '_annotations.txt'),\n",
    "    classes_file=os.path.join(config['data_path'], 'valid', '_classes.txt'),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4f45e7-7c18-488d-a096-a7f473836f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DrivingBehaviorDataset(\n",
    "    root_dir=os.path.join(config['data_path'], 'test'),\n",
    "    annotations_file=os.path.join(config['data_path'], 'test', '_annotations.txt'),\n",
    "    classes_file=os.path.join(config['data_path'], 'test', '_classes.txt'),\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48cfef6d-03fe-4bf9-afba-fc40e988f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41af9ae5-cd0b-44b4-9b7e-18a9f9c99651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教师模型（EfficientNetV2）\n",
    "teacher_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)  # 推荐使用 DEFAULT\n",
    "teacher_model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False)\n",
    "teacher_model.classifier[1] = nn.Linear(1280, config['num_classes'])\n",
    "teacher_model = teacher_model.to(config['device'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1def58f-64fc-4a78-b754-e909309d1d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学生模型（MobileNetV3 Small）\n",
    "student_model = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "student_model.classifier[3] = nn.Linear(1024, config['num_classes'])\n",
    "student_model = student_model.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4760cd61-acc2-4a6b-9402-11bb8ad003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edd6688f-3014-4844-b250-0533beafa3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet_V2_S_Weights.IMAGENET1K_V1\n"
     ]
    }
   ],
   "source": [
    "print(models.EfficientNet_V2_S_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeae38d2-5f7f-436f-ae37-484a1d34b113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(teacher_model.features[0][0].in_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d2809c-245b-456c-a043-4be6c1e17658",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationLoss(nn.Module):\n",
    "    def __init__(self, temperature, alpha):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.alpha = alpha\n",
    "        self.hard_loss = nn.CrossEntropyLoss()\n",
    "        self.kl_div = nn.KLDivLoss()\n",
    "\n",
    "    def forward(self, y_s, y_t, labels):\n",
    "        soft_loss = self.kl_div(\n",
    "            torch.log_softmax(y_s / self.temperature, dim=1),\n",
    "            torch.softmax(y_t / self.temperature, dim=1)\n",
    "        )\n",
    "        hard_loss = self.hard_loss(y_s, labels)\n",
    "        return (1 - self.alpha) * soft_loss * (self.temperature**2) + self.alpha * hard_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be604b8a-d584-4510-9d56-32cfbd3fa738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, teacher, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_logits = teacher(inputs)\n",
    "        student_logits = model(inputs)\n",
    "\n",
    "        loss = loss_fn(student_logits, teacher_logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = student_logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8df38c78-2644-4c18-af63-f5aafd2c90fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return correct / total, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef84857c-223a-4fcd-a75b-b272e1b8e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a4c2ac7-3d3b-4c2c-9320-ff3dcffe8774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    try:\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    except Exception as e:\n",
    "        print(f\"绘图失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c80d6a-f1bf-4caf-b72d-450ccce5403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_plots():\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.ion()\n",
    "\n",
    "def update_plots(epoch, train_loss, train_acc, val_loss, val_acc, losses, accuracies):\n",
    "    epochs = list(range(1, epoch + 2))\n",
    "    losses['train'].append(train_loss)\n",
    "    losses['val'].append(val_loss)\n",
    "    accuracies['train'].append(train_acc)\n",
    "    accuracies['val'].append(val_acc)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses['train'], label='Train Loss')\n",
    "    plt.plot(epochs, losses['val'], label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracies['train'], label='Train Acc')\n",
    "    plt.plot(epochs, accuracies['val'], label='Val Acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93ab4c-5022-485f-b80e-effd1d12c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, data_loader, device, class_names, num_images=6):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size(0)):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Pred: {class_names[preds[j]]} | True: {class_names[labels[j]]}')\n",
    "                plt.imshow(inputs[j].cpu().permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    plt.show()\n",
    "                    return\n",
    "\n",
    "# 主训练流程\n",
    "def main():\n",
    "    teacher = teacher_model\n",
    "    student = student_model\n",
    "\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    optimizer = optim.AdamW(student.parameters(), lr=config['lr'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "    loss_fn = DistillationLoss(config['temperature'], config['alpha'])\n",
    "\n",
    "    best_acc = 0\n",
    "    losses = {'train': [], 'val': []}\n",
    "    accuracies = {'train': [], 'val': []}\n",
    "    initialize_plots()\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        train_loss, train_acc = train_epoch(student, teacher, train_loader, optimizer, loss_fn, config['device'])\n",
    "        val_acc, _, _ = evaluate(student, val_loader, config['device'])\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "        scheduler.step(train_loss)\n",
    "\n",
    "        update_plots(epoch, train_loss, train_acc, train_loss, val_acc, losses, accuracies)\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(student.state_dict(), 'best_student_model.pth')\n",
    "\n",
    "    student.load_state_dict(torch.load('best_student_model.pth'))\n",
    "    test_acc, preds, labels = evaluate(student, test_loader, config['device'])\n",
    "    print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(labels, preds))\n",
    "\n",
    "    class_names = ['DangerousDriving', 'Distracted', 'Drinking', 'SafeDriving', 'SleepyDriving', 'Yawn']\n",
    "    plot_confusion_matrix(labels, preds, class_names)\n",
    "    show_predictions(student, test_loader, config['device'], class_names, num_images=6)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7284dfa-2832-4271-82f0-30b18b3e25d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
